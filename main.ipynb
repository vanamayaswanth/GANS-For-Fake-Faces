{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GANS for image generation\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.fc1 = nn.Linear(self.latent_dim, 128*4*4)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.conv1 = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.ConvTranspose2d(64, 32, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.ConvTranspose2d(32, 3, 4, 2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, 128, 4, 4)\n",
    "        x = self.relu(self.bn1(x))\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.bn2(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.bn3(x))\n",
    "        x = self.conv3(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(256, 1, 4, 1, 0)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#DataLoader\n",
    "def get_data_loader(batch_size, img_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(root='data/faces', transform=transform),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "#Training\n",
    "def train(batch_size, latent_dim, img_size, num_epochs):\n",
    "    data_loader = get_data_loader(batch_size, img_size)\n",
    "    G = Generator(latent_dim, img_size).to(device)\n",
    "    D = Discriminator(img_size).to(device)\n",
    "    G_optim = optim.Adam(G.parameters(), lr=0.0002)\n",
    "    D_optim = optim.Adam(D.parameters(), lr=0.0002)\n",
    "    criterion = nn.BCELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (imgs, _) in enumerate(data_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            batch_size = imgs.size(0)\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            #Train D\n",
    "            D.zero_grad()\n",
    "            real_output = D(imgs)\n",
    "            D_real_loss = criterion(real_output, real_labels)\n",
    "            D_real_loss.backward()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_imgs = G(z)\n",
    "            fake_output = D(fake_imgs)\n",
    "            D_fake_loss = criterion(fake_output, fake_labels)\n",
    "            D_fake_loss.backward()\n",
    "            D_loss = D_real_loss + D_fake_loss\n",
    "            D_optim.step()\n",
    "            #Train G\n",
    "            G.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_imgs = G(z)\n",
    "            fake_output = D(fake_imgs)\n",
    "            G_loss = criterion(fake_output, real_labels)\n",
    "            G_loss.backward()\n",
    "            G_optim.step()\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], D_loss: {:.4f}, G_loss: {:.4f}'\n",
    "                      .format(epoch, num_epochs, i, len(data_loader), D_loss.item(), G_loss.item()))\n",
    "\n",
    "\n",
    "#Testing\n",
    "def test(batch_size, latent_dim, img_size):\n",
    "    G = Generator(latent_dim, img_size).to(device)\n",
    "    z = torch.randn(batch_size, latent_dim).to(device)\n",
    "    fake_imgs = G(z)\n",
    "    save_image(fake_imgs, 'fake_imgs.png')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('gr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90c985cc047d5a65037cfccd0e7eba3544fde910f643ecb3dc813af6d7189d16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
